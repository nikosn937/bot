import streamlit as st
import pandas as pd
import gspread
from datetime import datetime
import re # Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î³Î¹Î± Ï„Î¿Î½ Î­Î»ÎµÎ³Ï‡Î¿ ÎµÎ³ÎºÏ…ÏÏŒÏ„Î·Ï„Î±Ï‚

# --------------------------------------------------------------------------------
# 0. Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ (CONNECTION & FORMATS)
# --------------------------------------------------------------------------------

@st.cache_resource
def get_gspread_client():
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î¿Î½ gspread client."""
    try:
        service_account_info = dict(st.secrets["gcp_service_account"])
        service_account_info['private_key'] = service_account_info['private_key'].replace('\\n', '\n')
        gc = gspread.service_account_from_dict(service_account_info)
        return gc
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ gspread. Î•Î»Î­Î³Î¾Ï„Îµ Ï„Î± secrets.toml ÎºÎ±Î¹ Ï„Î± Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±. Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚: {e}")
        return None

gc = get_gspread_client()
SHEET_NAME = st.secrets["sheet_name"] 
DATE_FORMAT = '%d/%m/%Y'

# --------------------------------------------------------------------------------
# 1. Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ•Î£ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î•Î™Î£
# --------------------------------------------------------------------------------

TONES_MAP = str.maketrans("Î¬Î­Î®Î¯ÏŒÏÏ", "Î±ÎµÎ·Î¹Î¿Ï…Ï")

def normalize_text(text):
    """ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÏƒÎµ Ï€ÎµÎ¶Î¬, Î±Ï†Î±Î¹ÏÎµÎ¯ Ï„Î± ÎºÎµÎ½Î¬ ÎºÎ±Î¹ Ï„Î¿Ï…Ï‚ Ï„ÏŒÎ½Î¿Ï…Ï‚."""
    if pd.isna(text): return ''
    normalized = str(text).lower().strip()
    return normalized.translate(TONES_MAP)

def get_tags_from_keyword(keyword):
    """Î”Î¹Î±Ï‡Ï‰ÏÎ¯Î¶ÎµÎ¹ Î¼Î¹Î± Ï†ÏÎ¬ÏƒÎ·-ÎºÎ»ÎµÎ¹Î´Î¯ ÏƒÎµ Î¼ÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î±, Î¿Î¼Î±Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± tags."""
    if not keyword or pd.isna(keyword): return []
    return [normalize_text(word) for word in str(keyword).split() if word]

@st.cache_data(ttl=600)
def load_data():
    """Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹, ÎºÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ ÎºÎ±Î¹ Ï„Î±Î¾Î¹Î½Î¿Î¼ÎµÎ¯ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ Ï„Î¿ ÎµÎ½Î¹Î±Î¯Î¿ Google Sheet."""
    if gc is None:
        return pd.DataFrame(), [], []

    try:
        sh = gc.open(SHEET_NAME)
        ws = sh.get_worksheet(0)
        data = ws.get_all_values()
        
        headers = data[0] if data else []
        df = pd.DataFrame(data[1:], columns=headers) 
        df.columns = df.columns.str.strip()
        
        required_cols = ['Keyword', 'Info', 'URL', 'Type', 'Date', 'School', 'Tmima']
        if not all(col in df.columns for col in required_cols):
            st.error(f"Î£Ï†Î¬Î»Î¼Î± Î´Î¿Î¼Î®Ï‚ Sheet: ÎŸÎ¹ ÎµÏ€Î¹ÎºÎµÏ†Î±Î»Î¯Î´ÎµÏ‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹: {', '.join(required_cols)}.")
            return pd.DataFrame(), [], []
        
        # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚/Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        df = df.dropna(subset=['Keyword', 'Date', 'School', 'Tmima'], how='any') 
        df['Date'] = pd.to_datetime(df['Date'], format=DATE_FORMAT, errors='coerce')
        df = df.dropna(subset=['Date'])
        
        # Î•Î¾Î±Î³Ï‰Î³Î® Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ Î£Ï‡Î¿Î»ÎµÎ¯Ï‰Î½ ÎºÎ±Î¹ Î¤Î¼Î·Î¼Î¬Ï„Ï‰Î½ Î´Ï…Î½Î±Î¼Î¹ÎºÎ¬
        available_schools = sorted(df['School'].unique().tolist()) if 'School' in df.columns else []
        available_tmimata = sorted(df['Tmima'].unique().tolist()) if 'Tmima' in df.columns else []
        
        return df, available_schools, available_tmimata
        
    except gspread.exceptions.SpreadsheetNotFound:
        st.error(f"Î£Ï†Î¬Î»Î¼Î±: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Google Sheet Î¼Îµ ÏŒÎ½Î¿Î¼Î±: '{SHEET_NAME}'. Î•Î»Î­Î³Î¾Ï„Îµ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± ÏƒÏ„Î± secrets.")
        return pd.DataFrame(), [], []
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚/ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½. Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚: {e}")
        return pd.DataFrame(), [], []

def create_search_maps(df):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿Ï…Ï‚ Ï‡Î¬ÏÏ„ÎµÏ‚ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ Î¼ÎµÏ„Î¬ Ï„Î¿ Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î±."""
    df_sorted = df.sort_values(by=['Keyword', 'Date'], ascending=[True, False])
    
    # Î¤Î¿ zip Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ 6 ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± (Info, URL, Type, Date, School, Tmima)
    keyword_to_data_map = df_sorted.groupby('Keyword').apply(
        lambda x: list(zip(x['Info'], x['URL'], x['Type'], x['Date'], x['School'], x['Tmima']))
    ).to_dict()

    tag_to_keyword_map = {}
    unique_keywords = df_sorted['Keyword'].unique()
    for keyword in unique_keywords:
        normalized_tags = get_tags_from_keyword(keyword)
        for tag in normalized_tags:
            if tag not in tag_to_keyword_map:
                tag_to_keyword_map[tag] = set()
            tag_to_keyword_map[tag].add(keyword)
            
    return tag_to_keyword_map, keyword_to_data_map


# --------------------------------------------------------------------------------
# 2. Î¦ÎŸÎ¡ÎœÎ‘ ÎšÎ‘Î¤Î‘Î§Î©Î¡Î—Î£Î—Î£
# --------------------------------------------------------------------------------

def submit_entry(new_entry_list):
    """Î ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Î¼Î¹Î± Î½Î­Î± ÏƒÎµÎ¹ÏÎ¬ ÏƒÏ„Î¿ Google Sheet."""
    if gc is None:
        st.error("Î— ÏƒÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ Google Sheets Î±Ï€Î­Ï„Ï…Ï‡Îµ.")
        return

    try:
        sh = gc.open(SHEET_NAME)
        ws = sh.get_worksheet(0)
        
        ws.append_row(new_entry_list)
        
        st.cache_data.clear() 
        st.success("ğŸ‰ Î— ÎºÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· Î­Î³Î¹Î½Îµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚! Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î±Î½Î±Î½ÎµÏÎ½ÎµÏ„Î±Î¹...")
        st.balloons()
        st.rerun() 
        
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎºÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·. Î•Î»Î­Î³Î¾Ï„Îµ Ï„Î± Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±. Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚: {e}")

def data_entry_form(available_schools, available_tmimata):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î· Ï†ÏŒÏÎ¼Î± ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î®Ï‚ Î½Î­Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½."""
    
    with st.expander("â• ÎÎ­Î± ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·"):
        
        st.markdown("### Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÎÎ­Î±Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±Ï‚")
        
        # 1. Î•Î Î™Î›ÎŸÎ“Î— Î£Î§ÎŸÎ›Î•Î™ÎŸÎ¥ & Î¤ÎœÎ—ÎœÎ‘Î¤ÎŸÎ£
        new_school = st.selectbox(
            "Î£Ï‡Î¿Î»ÎµÎ¯Î¿:", 
            options=sorted(list(set(available_schools))),
            key="form_school"
        )
        
        # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ text_input Î³Î¹Î± Ï„Î¿ Î¤Î¼Î®Î¼Î± ÏÏƒÏ„Îµ Î½Î± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î²Î¬Î»ÎµÎ¹ ÎºÎ±Î¹ Î½Î­Î± Ï„Î¼Î®Î¼Î±Ï„Î±
        new_tmima_input = st.text_input(
            "Î¤Î¼Î®Î¼Î± (Tmima):", 
            placeholder="Î .Ï‡. Î‘1, Î’2, Î“3",
            key="form_tmima"
        )
        
        # 2. Î¤Î¿ Radio Button Î•ÎÎ© Î±Ï€ÏŒ Ï„Î¿ Form (Î“Î¹Î± Î¬Î¼ÎµÏƒÎ¿ rerun/UX fix)
        if 'entry_type' not in st.session_state:
            st.session_state['entry_type'] = 'Text'
            
        st.session_state.entry_type = st.radio(
            "Î¤ÏÏ€Î¿Ï‚ ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚", 
            ('Text', 'Link'), 
            horizontal=True,
            key="radio_type_key"
        )
        
        new_url = ""
        
        # 3. Î†Î¼ÎµÏƒÎ· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… Ï€ÎµÎ´Î¯Î¿Ï… URL Î±Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯
        if st.session_state.entry_type == 'Link':
            st.session_state['new_url_value'] = st.text_input(
                "Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚ (URL)", 
                key="u1_link_input",
                placeholder="Î ÏÎ¿ÏƒÎ¸Î­ÏƒÏ„Îµ Î­Î½Î±Î½ URL, ÏƒÏÎ½Î´ÎµÏƒÎ¼Î¿ Google Drive, ÎºÎ»Ï€."
            )
            new_url = st.session_state.get('new_url_value', "")
        
        # 4. Î¦ÎŸÎ¡ÎœÎ‘ Î¥Î ÎŸÎ’ÎŸÎ›Î—Î£ (Î¼Îµ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± Ï€ÎµÎ´Î¯Î±)
        with st.form("new_entry_form", clear_on_submit=True):
            
            new_keyword = st.text_input("Î¦ÏÎ¬ÏƒÎ·-ÎšÎ»ÎµÎ¹Î´Î¯ (Keyword, Ï€.Ï‡. 'ÎµÏÎ³Î±ÏƒÎ¹Î± Î¼Î±Î¸Î·Î¼Î±Ï„Î¹ÎºÎ±')", key="k1_form")

            if st.session_state.entry_type == 'Text':
                new_info = st.text_area("Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® (Info)", key="i1_text_area")
            else: 
                new_info = st.text_input("Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î£Ï…Î½Î´Î­ÏƒÎ¼Î¿Ï… (Info)", key="i2_text_input")

            new_date_obj = st.date_input("Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚ (Date)", value=datetime.today().date(), key="d1_date")
            new_date_str = new_date_obj.strftime(DATE_FORMAT)
            
            submitted = st.form_submit_button("ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· ğŸ’¾")
            
            if submitted:
                final_url = new_url.strip() if st.session_state.entry_type == 'Link' else ""
                
                # Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· https://
                if final_url and st.session_state.entry_type == 'Link':
                    if not final_url.lower().startswith(('http://', 'https://', 'ftp://')):
                        final_url = 'https://' + final_url
                
                # --------------------------------------------------------
                # ÎÎ•ÎŸÎ£ ÎšÎ©Î”Î™ÎšÎ‘Î£: Î•Î›Î•Î“Î§ÎŸÎ£ Î•Î“ÎšÎ¥Î¡ÎŸÎ¤Î—Î¤Î‘Î£ Î¤ÎœÎ—ÎœÎ‘Î¤ÎŸÎ£ (Tmima)
                # --------------------------------------------------------
                
                tmima_check = new_tmima_input.strip().upper().replace(" ", "")

                # Pattern: ÎœÏŒÎ½Î¿ Î•Î»Î»Î·Î½Î¹ÎºÎ¬ ÎšÎµÏ†Î±Î»Î±Î¯Î± (Î‘-Î©) Î® Î‘ÏÎ¹Î¸Î¼Î¿Î¯ (0-9)
                tmima_pattern = re.compile(r'^[Î‘-Î©0-9]+$')

                if not tmima_pattern.match(tmima_check):
                    st.error("âš ï¸ Î£Ï†Î¬Î»Î¼Î± Î¤Î¼Î®Î¼Î±Ï„Î¿Ï‚: Î¤Î¿ Ï€ÎµÎ´Î¯Î¿ 'Î¤Î¼Î®Î¼Î±' Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Î¼ÏŒÎ½Î¿ **Î•Î»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚** ÎºÎµÏ†Î±Î»Î±Î¯Î¿Ï…Ï‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ (Î‘, Î’, Î“...) ÎºÎ±Î¹ **Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚** (1, 2, 3...), Ï‡Ï‰ÏÎ¯Ï‚ ÎºÎµÎ½Î¬.")
                    st.stop() # Î£Ï„Î±Î¼Î±Ï„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Î±Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Î¿ Î­Î»ÎµÎ³Ï‡Î¿Ï‚

                final_tmima = tmima_check 
                # --------------------------------------------------------
                
                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Ï€Î»Î·ÏÏŒÏ„Î·Ï„Î±Ï‚
                if not new_keyword or not new_info or not new_school or not final_tmima or (st.session_state.entry_type == 'Link' and not final_url):
                    st.error("Î Î±ÏÎ±ÎºÎ±Î»Ï ÏƒÏ…Î¼Ï€Î»Î·ÏÏÏƒÏ„Îµ ÏŒÎ»Î± Ï„Î± Ï€ÎµÎ´Î¯Î± (Î¦ÏÎ¬ÏƒÎ·-ÎšÎ»ÎµÎ¹Î´Î¯, Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®, Î£Ï‡Î¿Î»ÎµÎ¯Î¿, Î¤Î¼Î®Î¼Î± ÎºÎ±Î¹ Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿ Î±Î½ ÎµÎ¯Î½Î±Î¹ Link).")
                else:
                    new_entry_list = [
                        new_keyword.strip(), 
                        new_info.strip(), 
                        final_url, 
                        st.session_state.entry_type, 
                        new_date_str,
                        new_school,  # Î£Ï‡Î¿Î»ÎµÎ¯Î¿
                        final_tmima  # Î¤Ï…Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ (Î•Î»Î»Î·Î½Î¹ÎºÎ¬/ÎšÎµÏ†Î±Î»Î±Î¯Î±/Ï‡Ï‰ÏÎ¯Ï‚ ÎºÎµÎ½Î¬)
                    ]
                    submit_entry(new_entry_list)
                    
# --------------------------------------------------------------------------------
# 3. UI / ÎšÎ¥Î¡Î™Î‘ Î›ÎŸÎ“Î™ÎšÎ—
# --------------------------------------------------------------------------------

st.set_page_config(page_title="Î’Î¿Î·Î¸ÏŒÏ‚ Î¤Î¬Î¾Î·Ï‚ (gspread)", layout="centered")
st.title("ğŸ¤– Î¨Î·Ï†Î¹Î±ÎºÏŒÏ‚ Î’Î¿Î·Î¸ÏŒÏ‚ Î¤Î¬Î¾Î·Ï‚ (gspread Multi-School/Tmima)")
st.markdown("---")

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï„Ï‰Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ ÎµÏ€Î¹Î»Î¿Î³ÏÎ½
full_df, available_schools, available_tmimata = load_data()


# 1. Î•Î Î™Î›ÎŸÎ“Î— Î£Î§ÎŸÎ›Î•Î™ÎŸÎ¥
selected_school = st.selectbox(
    "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î£Ï‡Î¿Î»ÎµÎ¯Î¿:",
    options=["-- Î•Ï€Î¹Î»Î­Î¾Ï„Îµ --"] + available_schools,
    key="school_selector"
)

# 2. Î¦Î™Î›Î¤Î¡Î‘Î¡Î™Î£ÎœÎ‘ DF Î±Î½Î¬ Î£Î§ÎŸÎ›Î•Î™ÎŸ
if selected_school and selected_school != "-- Î•Ï€Î¹Î»Î­Î¾Ï„Îµ --" and not full_df.empty:
    
    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î²Î¬ÏƒÎµÎ¹ Ï„Î¿Ï… ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï… ÏƒÏ‡Î¿Î»ÎµÎ¯Î¿Ï…
    filtered_df_school = full_df[full_df['School'] == selected_school].copy()
    
    # Î•ÏÏÎµÏƒÎ· Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ Î³Î¹Î± Ï„Î¿ ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ ÏƒÏ‡Î¿Î»ÎµÎ¯Î¿
    current_tmimata = sorted(filtered_df_school['Tmima'].unique().tolist())
    
    # 3. Î•Î Î™Î›ÎŸÎ“Î— Î¤ÎœÎ—ÎœÎ‘Î¤ÎŸÎ£
    selected_tmima = st.selectbox(
        "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î¤Î¼Î®Î¼Î±:",
        options=["ÎŒÎ»Î± Ï„Î± Î¤Î¼Î®Î¼Î±Ï„Î±"] + current_tmimata,
        key="tmima_selector"
    )

    # 4. Î¤Î•Î›Î™ÎšÎŸ Î¦Î™Î›Î¤Î¡Î‘Î¡Î™Î£ÎœÎ‘ DF Î±Î½Î¬ Î¤ÎœÎ—ÎœÎ‘
    if selected_tmima != "ÎŒÎ»Î± Ï„Î± Î¤Î¼Î®Î¼Î±Ï„Î±":
        filtered_df = filtered_df_school[filtered_df_school['Tmima'] == selected_tmima]
    else:
        filtered_df = filtered_df_school

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï‡Î±ÏÏ„ÏÎ½ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î± Ï†Î¹Î»Ï„ÏÎ±ÏÎ¹ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    tag_to_keyword_map, keyword_to_data_map = create_search_maps(filtered_df)
    current_available_keys = sorted(filtered_df['Keyword'].unique().tolist())
    
    
    # 5. Î¦ÎŸÎ¡ÎœÎ‘ ÎšÎ‘Î¤Î‘Î§Î©Î¡Î—Î£Î—Î£
    data_entry_form(available_schools, available_tmimata) 
    
    st.markdown("---")
    st.header(f"ğŸ” Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½ Î³Î¹Î±: {selected_school} ({selected_tmima})")
    
    info_message = f"Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ Ï†ÏÎ¬ÏƒÎµÎ¹Ï‚-ÎºÎ»ÎµÎ¹Î´Î¹Î¬: **{', '.join(current_available_keys)}**" if current_available_keys else "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ Ï†ÏÎ¬ÏƒÎµÎ¹Ï‚-ÎºÎ»ÎµÎ¹Î´Î¹Î¬ Î³Î¹Î± Î±Ï…Ï„Î¬ Ï„Î± ÎºÏÎ¹Ï„Î®ÏÎ¹Î±."
    st.info(info_message)

    user_input = st.text_input(
        'Î¤Î¹ Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± Î¼Î¬Î¸ÎµÎ¹Ï‚;', 
        placeholder='Î Î»Î·ÎºÏ„ÏÎ¿Î»ÏŒÎ³Î·ÏƒÎµ Ï€.Ï‡. ÎµÎºÎ´ÏÎ¿Î¼Î·, ÎµÏÎ³Î±ÏƒÎ¹Î±, Î²Î¹Î²Î»Î¹Î±...'
    )

    if user_input and keyword_to_data_map:
        # Î›Î¿Î³Î¹ÎºÎ® Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ 
        search_tag = normalize_text(user_input)
        matching_keywords = tag_to_keyword_map.get(search_tag, set())
        
        if matching_keywords:
            all_results = []
            
            for keyword in matching_keywords:
                # Î¤Î¿ zip Î­Ï‡ÎµÎ¹ 6 ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±: (Info, URL, Type, Date, School, Tmima)
                all_results.extend(keyword_to_data_map.get(keyword, [])) 

            st.success(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ **{len(all_results)}** Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚.")

            for i, (info, url, item_type, date_obj, school, tmima) in enumerate(all_results, 1):
                date_str = date_obj.strftime(DATE_FORMAT) if pd.notna(date_obj) else "Î†Î³Î½Ï‰ÏƒÏ„Î· Î—Î¼/Î½Î¯Î±"
                header = f"**ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· {i}** ({school} - {tmima} | Î—Î¼/Î½Î¯Î±: {date_str})"
                
                if item_type.strip().lower() == 'link': 
                    link_description = info.strip()
                    link_url = url.strip()
                    if link_url:
                        st.markdown(f"{header}: ğŸ”— [{link_description}](<{link_url}>)") 
                    else:
                        st.markdown(f"{header}: âš ï¸ **Î ÏÎ¿ÏƒÎ¿Ï‡Î®:** ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· ÏƒÏ…Î½Î´Î­ÏƒÎ¼Î¿Ï… Ï‡Ï‰ÏÎ¯Ï‚ URL. Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®: {link_description}")
                
                elif item_type.strip().lower() == 'text':
                    st.markdown(f"{header}: ğŸ’¬ {info}")
                
                else:
                    st.markdown(f"{header}: Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ Î¤ÏÏ€Î¿Ï‚ ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚. {info}")
                    
        else:
            st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î³Î¹Î± Ï„Î¿: '{user_input}'.")

    st.markdown("---")

elif full_df.empty:
    st.warning("Î Î±ÏÎ±ÎºÎ±Î»Ï ÏƒÏ…Î¼Ï€Î»Î·ÏÏÏƒÏ„Îµ Ï„Î¿ Google Sheet Î¼Îµ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ 'School' ÎºÎ±Î¹ 'Tmima'.")
else:
    st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Î£Ï‡Î¿Î»ÎµÎ¯Î¿ Î³Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹ Î· Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·.")


st.caption("Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î´Î¹Î±Î²Î¬Î¶Î¿Î½Ï„Î±Î¹ ÎºÎ±Î¹ Î³ÏÎ¬Ï†Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿ Google Sheet Î¼Î­ÏƒÏ‰ Ï„Î·Ï‚ Î²Î±ÏƒÎ¹ÎºÎ®Ï‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·Ï‚ gspread.")
