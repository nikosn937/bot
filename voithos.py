import streamlit as st
import pandas as pd

# --------------------------------------------------------------------------------
# 1. Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ— Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î— (Î‘Î¦Î‘Î™Î¡Î•Î£Î— Î¤ÎŸÎÎ©Î)
# --------------------------------------------------------------------------------

TONES_MAP = str.maketrans("Î¬Î­Î®Î¯ÏŒÏÏ", "Î±ÎµÎ·Î¹Î¿Ï…Ï")

def normalize_keyword(keyword):
    """ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ Ï„Î· Î»Î­Î¾Î·-ÎºÎ»ÎµÎ¹Î´Î¯ ÏƒÎµ Ï€ÎµÎ¶Î¬, Î±Ï†Î±Î¹ÏÎµÎ¯ Ï„Î± ÎºÎµÎ½Î¬ ÎºÎ±Î¹ Ï„Î¿Ï…Ï‚ Ï„ÏŒÎ½Î¿Ï…Ï‚."""
    if pd.isna(keyword):
        return ''
    normalized = str(keyword).lower().strip()
    return normalized.translate(TONES_MAP)


# --------------------------------------------------------------------------------
# 2. Î¦ÎŸÎ¡Î¤Î©Î£Î— ÎšÎ‘Î™ Î•Î Î•ÎÎ•Î¡Î“Î‘Î£Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î Î‘Î ÎŸ CSV (5 Î£Î¤Î—Î›Î•Î£)
# --------------------------------------------------------------------------------

DATA_FILE = 'class_data.csv' 
DATE_FORMAT = '%d/%m/%Y' 

try:
    df = pd.read_csv(DATA_FILE, encoding='utf-8')
    df.columns = df.columns.str.strip()
    
    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÏÏ€Î±ÏÎ¾Î·Ï‚ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Ï‰Î½ ÏƒÏ„Î·Î»ÏÎ½
    required_cols = ['Keyword', 'Info', 'URL', 'Type', 'Date'] # Î•Î´Ï ÎµÎ¯Î½Î±Î¹ Î· Î±Î»Î»Î±Î³Î®
    if not all(col in df.columns for col in required_cols):
        raise ValueError(f"Î£Ï†Î¬Î»Î¼Î±: Î¤Î¿ CSV Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï„Î¹Ï‚ Î±ÎºÏÎ¹Î²ÎµÎ¯Ï‚ ÎµÏ€Î¹ÎºÎµÏ†Î±Î»Î¯Î´ÎµÏ‚: {', '.join(required_cols)}.")
    
    # 1. ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Î·Ï‚ ÏƒÏ„Î®Î»Î·Ï‚ Date
    df['Date'] = pd.to_datetime(df['Date'], format=DATE_FORMAT, errors='coerce')
    
    # 2. Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·
    df_sorted = df.sort_values(by=['Keyword', 'Date'], ascending=[True, False])
    
    # 3. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î¿Î¼Î±Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î·Ï‚ ÏƒÏ„Î®Î»Î·Ï‚
    df_sorted['Normalized_Keyword'] = df_sorted['Keyword'].apply(normalize_keyword)
    
    # 4. ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î£Ï…Î»Î»Î­Î³Î¿Ï…Î¼Îµ Ï„ÏÏÎ± 4 ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± (Info, URL, Type, Date)
    data_source_dict = df_sorted.groupby('Normalized_Keyword').apply(
        lambda x: list(zip(x['Info'], x['URL'], x['Type'], x['Date']))
    ).to_dict()
    
    available_keys_display = sorted(df['Keyword'].unique())
    
except Exception as e:
    st.error(f"ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ Î£Ï†Î¬Î»Î¼Î± Î¦ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½: {e}")
    data_source_dict = {}
    available_keys_display = []

# --------------------------------------------------------------------------------
# 3. UI / Î›ÎŸÎ“Î™ÎšÎ—
# --------------------------------------------------------------------------------

st.set_page_config(page_title="Î’Î¿Î·Î¸ÏŒÏ‚ Î¤Î¬Î¾Î·Ï‚ & Î‘ÏÏ‡ÎµÎ¯Î±", layout="centered")
st.title("ğŸ¤– Î¨Î·Ï†Î¹Î±ÎºÏŒÏ‚ Î’Î¿Î·Î¸ÏŒÏ‚ Î¤Î¬Î¾Î·Ï‚")
st.markdown("---")

info_message = f"Î“ÎµÎ¹Î±! Î•Î¯Î¼Î±Î¹ Î¿ Î²Î¿Î·Î¸ÏŒÏ‚ ÏƒÎ¿Ï…. Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ Î»Î­Î¾ÎµÎ¹Ï‚-ÎºÎ»ÎµÎ¹Î´Î¹Î¬: **{', '.join(available_keys_display)}**"
st.info(info_message)

user_input = st.text_input(
    'Î¤Î¹ Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± Î¼Î¬Î¸ÎµÎ¹Ï‚;', 
    placeholder='Î Î»Î·ÎºÏ„ÏÎ¿Î»ÏŒÎ³Î·ÏƒÎµ Ï€.Ï‡. ÎœÎ±Î¸Î·Î¼Î±Ï„Î¹ÎºÎ¬, Î¦Ï…ÏƒÎ¹ÎºÎ®...'
)

if user_input:
    processed_input = normalize_keyword(user_input)
    
    if processed_input in data_source_dict:
        # Î— Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± Î»Î¯ÏƒÏ„Î± Î±Ï€ÏŒ tuples: [(Info, URL, Type, Date), ...]
        list_of_items = data_source_dict[processed_input]
        
        st.success(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ **{len(list_of_items)}** Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚/Î±ÏÏ‡ÎµÎ¯Î± Î³Î¹Î± Ï„Î¿ Î¸Î­Î¼Î±: **{user_input}** (ÎŸÎ¹ Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„ÎµÏ‚ Ï€ÏÏÏ„ÎµÏ‚)")
        
        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎºÎ¬Î¸Îµ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚/Î±ÏÏ‡ÎµÎ¯Î¿Ï…
        for i, (info, url, item_type, date_obj) in enumerate(list_of_items, 1):
            
            date_str = date_obj.strftime(DATE_FORMAT) if pd.notna(date_obj) else "Î†Î³Î½Ï‰ÏƒÏ„Î· Î—Î¼/Î½Î¯Î±"
            header = f"**ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· {i}** (Î—Î¼/Î½Î¯Î±: {date_str})"
            
            if item_type.strip().lower() == 'file':
                # Î‘Î½ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡ÎµÎ¯Î¿, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ 'info' Ï‰Ï‚ Ï€ÎµÏÎ¹Î³ÏÎ±Ï†Î® Ï„Î¿Ï… link ÎºÎ±Î¹ Ï„Î¿ 'url' Ï‰Ï‚ ÏƒÏÎ½Î´ÎµÏƒÎ¼Î¿
                link_description = info.strip()
                link_url = url.strip()
                
                # Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ Î»Î¹Î½Îº Î¼ÏŒÎ½Î¿ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ URL
                if link_url:
                    st.markdown(f"{header}: ğŸ“‚ [{link_description}](<{link_url}>)")
                else:
                    st.markdown(f"{header}: ğŸ’¬ **Î ÏÎ¿ÏƒÎ¿Ï‡Î®:** Î— ÎºÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ ÏƒÏÎ½Î´ÎµÏƒÎ¼Î¿. Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®: {link_description}")
                
            elif item_type.strip().lower() == 'text':
                # Î‘Î½ ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î¿ 'info'
                st.markdown(f"{header}: ğŸ’¬ {info}")
            
            else:
                st.markdown(f"{header}: Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ Î¤ÏÏ€Î¿Ï‚ ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚. {info}")

    else:
        st.warning(
            f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î³Î¹Î± Ï„Î¿: '{user_input}'. Î”Î¿ÎºÎ¯Î¼Î±ÏƒÎµ Î¼Î¯Î± Î±Ï€ÏŒ Ï„Î¹Ï‚ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ Î»Î­Î¾ÎµÎ¹Ï‚-ÎºÎ»ÎµÎ¹Î´Î¹Î¬: **{', '.join(available_keys_display)}**."
        )

st.markdown("---")
st.caption("Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Python/Streamlit ÎºÎ±Î¹ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ class_data.csv.")
