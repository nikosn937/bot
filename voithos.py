import streamlit as st
import pandas as pd
import gspread
from datetime import datetime, timedelta # Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î³Î¹Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¹ÏÎ½
import re # Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î³Î¹Î± Ï„Î¿Î½ Î­Î»ÎµÎ³Ï‡Î¿ ÎµÎ³ÎºÏ…ÏÏŒÏ„Î·Ï„Î±Ï‚ Tmima

# --------------------------------------------------------------------------------
# 0. Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ (CONNECTION & FORMATS)
# --------------------------------------------------------------------------------

@st.cache_resource
def get_gspread_client():
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î¿Î½ gspread client."""
    try:
        service_account_info = dict(st.secrets["gcp_service_account"])
        # Î‘Î½Ï„Î¹ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Ï„Ï‰Î½ escape sequences Î³Î¹Î± Ï„Î· ÏƒÏ‰ÏƒÏ„Î® Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Ï„Î¿Ï… private key
        service_account_info['private_key'] = service_account_info['private_key'].replace('\\n', '\n')
        gc = gspread.service_account_from_dict(service_account_info)
        return gc
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ gspread. Î•Î»Î­Î³Î¾Ï„Îµ Ï„Î± secrets.toml ÎºÎ±Î¹ Ï„Î± Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±. Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚: {e}")
        return None

gc = get_gspread_client()
SHEET_NAME = st.secrets["sheet_name"] 
DATE_FORMAT = '%d/%m/%Y'

# --------------------------------------------------------------------------------
# 1. Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ•Î£ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î•Î™Î£
# --------------------------------------------------------------------------------

TONES_MAP = str.maketrans("Î¬Î­Î®Î¯ÏŒÏÏ", "Î±ÎµÎ·Î¹Î¿Ï…Ï")

def normalize_text(text):
    """ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÏƒÎµ Ï€ÎµÎ¶Î¬, Î±Ï†Î±Î¹ÏÎµÎ¯ Ï„Î± ÎºÎµÎ½Î¬ ÎºÎ±Î¹ Ï„Î¿Ï…Ï‚ Ï„ÏŒÎ½Î¿Ï…Ï‚ (Î³Î¹Î± Ï„Î·Î½ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·)."""
    if pd.isna(text): return ''
    normalized = str(text).lower().strip()
    return normalized.translate(TONES_MAP)

def get_tags_from_keyword(keyword):
    """Î”Î¹Î±Ï‡Ï‰ÏÎ¯Î¶ÎµÎ¹ Î¼Î¹Î± Ï†ÏÎ¬ÏƒÎ·-ÎºÎ»ÎµÎ¹Î´Î¯ ÏƒÎµ Î¼ÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î±, Î¿Î¼Î±Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± tags."""
    if not keyword or pd.isna(keyword): return []
    return [normalize_text(word) for word in str(keyword).split() if word]

@st.cache_data(ttl=600)
def load_data():
    """Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹, ÎºÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ ÎºÎ±Î¹ Ï„Î±Î¾Î¹Î½Î¿Î¼ÎµÎ¯ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ Ï„Î¿ ÎµÎ½Î¹Î±Î¯Î¿ Google Sheet."""
    if gc is None:
        return pd.DataFrame(), [], []

    try:
        sh = gc.open(SHEET_NAME)
        ws = sh.get_worksheet(0)
        data = ws.get_all_values()
        
        headers = data[0] if data else []
        df = pd.DataFrame(data[1:], columns=headers) 
        df.columns = df.columns.str.strip()
        
        required_cols = ['Keyword', 'Info', 'URL', 'Type', 'Date', 'School', 'Tmima']
        if not all(col in df.columns for col in required_cols):
            st.error(f"Î£Ï†Î¬Î»Î¼Î± Î´Î¿Î¼Î®Ï‚ Sheet: ÎŸÎ¹ ÎµÏ€Î¹ÎºÎµÏ†Î±Î»Î¯Î´ÎµÏ‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹: {', '.join(required_cols)}.")
            return pd.DataFrame(), [], []
        
        # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚/Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        df = df.dropna(subset=['Keyword', 'Date', 'School', 'Tmima'], how='any') 
        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Î·Ï‚ ÏƒÏ„Î®Î»Î·Ï‚ Date ÏƒÎµ Ï„ÏÏ€Î¿ datetime
        df['Date'] = pd.to_datetime(df['Date'], format=DATE_FORMAT, errors='coerce')
        df = df.dropna(subset=['Date'])
        
        # Î•Î¾Î±Î³Ï‰Î³Î® Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ Î£Ï‡Î¿Î»ÎµÎ¯Ï‰Î½ ÎºÎ±Î¹ Î¤Î¼Î·Î¼Î¬Ï„Ï‰Î½ Î´Ï…Î½Î±Î¼Î¹ÎºÎ¬
        available_schools = sorted(df['School'].unique().tolist()) if 'School' in df.columns else []
        available_tmimata = sorted(df['Tmima'].unique().tolist()) if 'Tmima' in df.columns else []
        
        return df, available_schools, available_tmimata
        
    except gspread.exceptions.SpreadsheetNotFound:
        st.error(f"Î£Ï†Î¬Î»Î¼Î±: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Google Sheet Î¼Îµ ÏŒÎ½Î¿Î¼Î±: '{SHEET_NAME}'. Î•Î»Î­Î³Î¾Ï„Îµ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± ÏƒÏ„Î± secrets.")
        return pd.DataFrame(), [], []
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚/ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½. Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚: {e}")
        return pd.DataFrame(), [], []

def create_search_maps(df):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿Ï…Ï‚ Ï‡Î¬ÏÏ„ÎµÏ‚ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ Î¼ÎµÏ„Î¬ Ï„Î¿ Ï†Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î±."""
    df_sorted = df.sort_values(by=['Keyword', 'Date'], ascending=[True, False])
    
    # Î¤Î¿ zip Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ 6 ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± (Info, URL, Type, Date, School, Tmima)
    keyword_to_data_map = df_sorted.groupby('Keyword').apply(
        lambda x: list(zip(x['Info'], x['URL'], x['Type'], x['Date'], x['School'], x['Tmima']))
    ).to_dict()

    tag_to_keyword_map = {}
    unique_keywords = df_sorted['Keyword'].unique()
    for keyword in unique_keywords:
        normalized_tags = get_tags_from_keyword(keyword)
        for tag in normalized_tags:
            if tag not in tag_to_keyword_map:
                tag_to_keyword_map[tag] = set()
            tag_to_keyword_map[tag].add(keyword)
            
    return tag_to_keyword_map, keyword_to_data_map


# --------------------------------------------------------------------------------
# 2. Î¦ÎŸÎ¡ÎœÎ‘ ÎšÎ‘Î¤Î‘Î§Î©Î¡Î—Î£Î—Î£
# --------------------------------------------------------------------------------

def submit_entry(new_entry_list):
    """Î ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Î¼Î¹Î± Î½Î­Î± ÏƒÎµÎ¹ÏÎ¬ ÏƒÏ„Î¿ Google Sheet."""
    if gc is None:
        st.error("Î— ÏƒÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ Google Sheets Î±Ï€Î­Ï„Ï…Ï‡Îµ.")
        return

    try:
        sh = gc.open(SHEET_NAME)
        ws = sh.get_worksheet(0)
        
        ws.append_row(new_entry_list)
        
        st.cache_data.clear() 
        st.success("ğŸ‰ Î— ÎºÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· Î­Î³Î¹Î½Îµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚! Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î±Î½Î±Î½ÎµÏÎ½ÎµÏ„Î±Î¹...")
        st.balloons()
        st.rerun() 
        
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎºÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·. Î•Î»Î­Î³Î¾Ï„Îµ Ï„Î± Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±. Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚: {e}")

def data_entry_form(available_schools, available_tmimata):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î· Ï†ÏŒÏÎ¼Î± ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î®Ï‚ Î½Î­Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½."""
    
    with st.expander("â• ÎÎ­Î± ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·"):
        
        st.markdown("### Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÎÎ­Î±Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±Ï‚ (ÎœÏŒÎ½Î¿ Î³Î¹Î± Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ¿ÏÏ‚)")
        
        # 1. Î•Î Î™Î›ÎŸÎ“Î— Î£Î§ÎŸÎ›Î•Î™ÎŸÎ¥ & Î¤ÎœÎ—ÎœÎ‘Î¤ÎŸÎ£
        new_school = st.selectbox(
            "Î£Ï‡Î¿Î»ÎµÎ¯Î¿:", 
            options=sorted(list(set(available_schools))),
            key="form_school"
        )
        
        # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ text_input Î³Î¹Î± Ï„Î¿ Î¤Î¼Î®Î¼Î± ÏÏƒÏ„Îµ Î½Î± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î²Î¬Î»ÎµÎ¹ ÎºÎ±Î¹ Î½Î­Î± Ï„Î¼Î®Î¼Î±Ï„Î±
        new_tmima_input = st.text_input(
            "Î¤Î¼Î®Î¼Î± (Tmima):", 
            placeholder="Î ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ Î•Î»Î»Î·Î½Î¹ÎºÎ¿Î¯ ÎšÎµÏ†Î±Î»Î±Î¯Î¿Î¹ (Î .Ï‡. Î‘1, Î“2)",
            key="form_tmima"
        )
        
        # 2. Î¤Î¿ Radio Button Î•ÎÎ© Î±Ï€ÏŒ Ï„Î¿ Form (Î“Î¹Î± Î¬Î¼ÎµÏƒÎ¿ rerun/UX fix)
        if 'entry_type' not in st.session_state:
            st.session_state['entry_type'] = 'Text'
            
        st.session_state.entry_type = st.radio(
            "Î¤ÏÏ€Î¿Ï‚ ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚", 
            ('Text', 'Link'), 
            horizontal=True,
            key="radio_type_key"
        )
        
        new_url = ""
        
        # 3. Î†Î¼ÎµÏƒÎ· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… Ï€ÎµÎ´Î¯Î¿Ï… URL Î±Î½ ÎµÏ€Î¹Î»ÎµÎ³ÎµÎ¯
        if st.session_state.entry_type == 'Link':
            st.session_state['new_url_value'] = st.text_input(
                "Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚ (URL)", 
                key="u1_link_input",
                placeholder="Î ÏÎ¿ÏƒÎ¸Î­ÏƒÏ„Îµ Î­Î½Î±Î½ URL, ÏƒÏÎ½Î´ÎµÏƒÎ¼Î¿ Google Drive, ÎºÎ»Ï€."
            )
            new_url = st.session_state.get('new_url_value', "")
        
        # 4. Î¦ÎŸÎ¡ÎœÎ‘ Î¥Î ÎŸÎ’ÎŸÎ›Î—Î£ (Î¼Îµ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± Ï€ÎµÎ´Î¯Î±)
        with st.form("new_entry_form", clear_on_submit=True):
            
            new_keyword = st.text_input("Î¦ÏÎ¬ÏƒÎ·-ÎšÎ»ÎµÎ¹Î´Î¯ (Keyword, Ï€.Ï‡. 'ÎµÏÎ³Î±ÏƒÎ¹Î± Î¼Î±Î¸Î·Î¼Î±Ï„Î¹ÎºÎ±')", key="k1_form")

            if st.session_state.entry_type == 'Text':
                new_info = st.text_area("Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® (Info)", key="i1_text_area")
            else: 
                new_info = st.text_input("Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î£Ï…Î½Î´Î­ÏƒÎ¼Î¿Ï… (Info)", key="i2_text_input")

            new_date_obj = st.date_input("Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚ (Date)", value=datetime.today().date(), key="d1_date")
            new_date_str = new_date_obj.strftime(DATE_FORMAT)
            
            submitted = st.form_submit_button("ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· ğŸ’¾")
            
            if submitted:
                final_url = new_url.strip() if st.session_state.entry_type == 'Link' else ""
                
                # Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· https://
                if final_url and st.session_state.entry_type == 'Link':
                    if not final_url.lower().startswith(('http://', 'https://', 'ftp://')):
                        final_url = 'https://' + final_url
                
                # --------------------------------------------------------
                # Î•Î›Î•Î“Î§ÎŸÎ£ Î•Î“ÎšÎ¥Î¡ÎŸÎ¤Î—Î¤Î‘Î£ Î¤ÎœÎ—ÎœÎ‘Î¤ÎŸÎ£ (Tmima) - Î•Î»Î»Î·Î½Î¹ÎºÎ¬/ÎšÎµÏ†Î±Î»Î±Î¯Î±
                # --------------------------------------------------------
                
                # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ ÎºÎµÏ†Î±Î»Î±Î¯Î± ÎºÎ±Î¹ Î±Ï†Î±Î¯ÏÎµÏƒÎ· ÎºÎµÎ½ÏÎ½ Î³Î¹Î± Ï„Î·Î½ Ï„ÎµÎ»Î¹ÎºÎ® ÎºÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·
                tmima_check = new_tmima_input.strip().upper().replace(" ", "")

                # Pattern: ÎœÏŒÎ½Î¿ Î•Î»Î»Î·Î½Î¹ÎºÎ¬ ÎšÎµÏ†Î±Î»Î±Î¯Î± (Î‘-Î©) Î® Î‘ÏÎ¹Î¸Î¼Î¿Î¯ (0-9)
                tmima_pattern = re.compile(r'^[Î‘-Î©0-9]+$')

                if not tmima_pattern.match(tmima_check):
                    st.error("âš ï¸ Î£Ï†Î¬Î»Î¼Î± Î¤Î¼Î®Î¼Î±Ï„Î¿Ï‚: Î¤Î¿ Ï€ÎµÎ´Î¯Î¿ 'Î¤Î¼Î®Î¼Î±' Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Î¼ÏŒÎ½Î¿ **Î•Î»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚** ÎºÎµÏ†Î±Î»Î±Î¯Î¿Ï…Ï‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ (Î‘, Î’, Î“...) ÎºÎ±Î¹ **Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚** (1, 2, 3...), Ï‡Ï‰ÏÎ¯Ï‚ ÎºÎµÎ½Î¬. Î”Î¹Î¿ÏÎ¸ÏÏƒÏ„Îµ Ï„Î·Î½ ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® ÏƒÎ±Ï‚.")
                    st.stop() # Î£Ï„Î±Î¼Î±Ï„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Î±Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Î¿ Î­Î»ÎµÎ³Ï‡Î¿Ï‚

                final_tmima = tmima_check 
                # --------------------------------------------------------
                
                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Ï€Î»Î·ÏÏŒÏ„Î·Ï„Î±Ï‚
                if not new_keyword or not new_info or not new_school or not final_tmima or (st.session_state.entry_type == 'Link' and not final_url):
                    st.error("Î Î±ÏÎ±ÎºÎ±Î»Ï ÏƒÏ…Î¼Ï€Î»Î·ÏÏÏƒÏ„Îµ ÏŒÎ»Î± Ï„Î± Ï€ÎµÎ´Î¯Î± (Î¦ÏÎ¬ÏƒÎ·-ÎšÎ»ÎµÎ¹Î´Î¯, Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®, Î£Ï‡Î¿Î»ÎµÎ¯Î¿, Î¤Î¼Î®Î¼Î± ÎºÎ±Î¹ Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿ Î±Î½ ÎµÎ¯Î½Î±Î¹ Link).")
                else:
                    new_entry_list = [
                        new_keyword.strip(), 
                        new_info.strip(), 
                        final_url, 
                        st.session_state.entry_type, 
                        new_date_str,
                        new_school,  # Î£Ï‡Î¿Î»ÎµÎ¯Î¿
                        final_tmima  # Î¤Ï…Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ (Î•Î»Î»Î·Î½Î¹ÎºÎ¬/ÎšÎµÏ†Î±Î»Î±Î¯Î±/Ï‡Ï‰ÏÎ¯Ï‚ ÎºÎµÎ½Î¬)
                    ]
                    submit_entry(new_entry_list)
                    
# --------------------------------------------------------------------------------
# 3. UI / ÎšÎ¥Î¡Î™Î‘ Î›ÎŸÎ“Î™ÎšÎ—
# --------------------------------------------------------------------------------

st.set_page_config(page_title="Î’Î¿Î·Î¸ÏŒÏ‚ Î¤Î¬Î¾Î·Ï‚ (gspread)", layout="centered")
st.title("ğŸ¤– Î¨Î·Ï†Î¹Î±ÎºÏŒÏ‚ Î’Î¿Î·Î¸ÏŒÏ‚ Î¤Î¬Î¾Î·Ï‚ (gspread Multi-School/Tmima)")
st.markdown("---")

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï„Ï‰Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ ÎµÏ€Î¹Î»Î¿Î³ÏÎ½
full_df, available_schools, available_tmimata = load_data()


# 1. Î•Î Î™Î›ÎŸÎ“Î— Î£Î§ÎŸÎ›Î•Î™ÎŸÎ¥
selected_school = st.selectbox(
    "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î£Ï‡Î¿Î»ÎµÎ¯Î¿:",
    options=["-- Î•Ï€Î¹Î»Î­Î¾Ï„Îµ --"] + available_schools,
    key="school_selector"
)

# 2. Î¦Î™Î›Î¤Î¡Î‘Î¡Î™Î£ÎœÎ‘ DF Î±Î½Î¬ Î£Î§ÎŸÎ›Î•Î™ÎŸ
if selected_school and selected_school != "-- Î•Ï€Î¹Î»Î­Î¾Ï„Îµ --" and not full_df.empty:
    
    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î²Î¬ÏƒÎµÎ¹ Ï„Î¿Ï… ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï… ÏƒÏ‡Î¿Î»ÎµÎ¯Î¿Ï…
    filtered_df_school = full_df[full_df['School'] == selected_school].copy()
    
    # Î•ÏÏÎµÏƒÎ· Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ Î³Î¹Î± Ï„Î¿ ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ ÏƒÏ‡Î¿Î»ÎµÎ¯Î¿
    current_tmimata = sorted(filtered_df_school['Tmima'].unique().tolist())
    
    # --------------------------------------------------------------------------
    # Î›ÎŸÎ“Î™ÎšÎ—: Î¥Î ÎŸÎ§Î¡Î•Î©Î¤Î™ÎšÎ— Î•Î Î™Î›ÎŸÎ“Î— Î¤ÎœÎ—ÎœÎ‘Î¤ÎŸÎ£
    # --------------------------------------------------------------------------
    
    if not current_tmimata:
        # 3a. Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎºÎ±Ï„Î±Ï‡Ï‰ÏÎ®ÏƒÎµÎ¹Ï‚ Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ Î³Î¹Î± Ï„Î¿ ÏƒÏ‡Î¿Î»ÎµÎ¯Î¿
        st.warning(f"Î¤Î¿ Î£Ï‡Î¿Î»ÎµÎ¯Î¿ '{selected_school}' Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ ÎºÎ±Ï„Î±Ï‡Ï‰ÏÎ®ÏƒÎµÎ¹Ï‚ Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ ÏƒÏ„Î¿ ÏƒÏÏƒÏ„Î·Î¼Î±.")
        
        # Î”Î¯Î½Î¿Ï…Î¼Îµ Ï„Î· Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± ÎºÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚
        data_entry_form(available_schools, available_tmimata)

    else:
        # 3Î². Î¥Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ® ÎµÏ€Î¹Î»Î¿Î³Î® Î¤Î¼Î®Î¼Î±Ï„Î¿Ï‚
        selected_tmima = st.selectbox(
            "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î¤Î¼Î®Î¼Î± (Î¥Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÏŒ):", 
            options=current_tmimata,
            key="tmima_selector"
        )

        # 4. Î¤Î•Î›Î™ÎšÎŸ Î¦Î™Î›Î¤Î¡Î‘Î¡Î™Î£ÎœÎ‘ DF Î±Î½Î¬ Î¤ÎœÎ—ÎœÎ‘
        filtered_df = filtered_df_school[filtered_df_school['Tmima'] == selected_tmima]

        # ----------------------------------------------------------------------
        # Î•ÎœÎ¦Î‘ÎÎ™Î£Î— Î¤Î•Î›Î•Î¥Î¤Î‘Î™Î©Î 2 Î—ÎœÎ•Î¡Î©Î Î Î¡Î™Î Î¤Î—Î Î‘ÎÎ‘Î–Î—Î¤Î—Î£Î—
        # ----------------------------------------------------------------------
        
        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚ Î­Î½Î±ÏÎ¾Î·Ï‚: Î£Î®Î¼ÎµÏÎ± - 2 Î·Î¼Î­ÏÎµÏ‚
        two_days_ago = datetime.now() - timedelta(days=2)
        
        # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï„Î¿Ï… Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚ Î³Î¹Î± Ï„Î¹Ï‚ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯ÎµÏ‚ 2 Î·Î¼Î­ÏÎµÏ‚
        # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ .dt.date Î³Î¹Î± Î½Î± ÏƒÏ…Î³ÎºÏÎ¯Î½Î¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î·Î½ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±, Î´Î¹Î¿ÏÎ¸ÏÎ½Î¿Î½Ï„Î±Ï‚ Ï„Î¿ TypeError
        recent_posts = filtered_df[filtered_df['Date'].dt.date >= two_days_ago.date()]
        
        if not recent_posts.empty:
            st.header(f"ğŸ“¢ Î ÏÏŒÏƒÏ†Î±Ï„ÎµÏ‚ Î‘Î½Î±ÎºÎ¿Î¹Î½ÏÏƒÎµÎ¹Ï‚ ({selected_tmima})")
            st.info("Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¿Î¹ ÎºÎ±Ï„Î±Ï‡Ï‰ÏÎ®ÏƒÎµÎ¹Ï‚ Ï„Ï‰Î½ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Ï‰Î½ 2 Î·Î¼ÎµÏÏÎ½.")
            
            # Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Ï„Ï‰Î½ Ï€ÏÏŒÏƒÏ†Î±Ï„Ï‰Î½ Î´Î·Î¼Î¿ÏƒÎ¹ÎµÏÏƒÎµÏ‰Î½ (Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î· Ï€ÏÏÏ„Î·)
            recent_posts = recent_posts.sort_values(by='Date', ascending=False)
            
            # Rendering Ï„Ï‰Î½ Ï€ÏÏŒÏƒÏ†Î±Ï„Ï‰Î½ Î´Î·Î¼Î¿ÏƒÎ¹ÎµÏÏƒÎµÏ‰Î½
            for i, row in recent_posts.iterrows():
                date_str = row['Date'].strftime(DATE_FORMAT)
                header = f"**ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· (Î‘Ï€ÏŒ: {date_str})**"
                
                if row['Type'].strip().lower() == 'link': 
                    link_description = row['Info'].strip()
                    link_url = row['URL'].strip()
                    st.markdown(f"{header}: ğŸ”— [{link_description}](<{link_url}>) (Keyword: *{row['Keyword']}*)")
                
                elif row['Type'].strip().lower() == 'text':
                    st.markdown(f"{header}: ğŸ’¬ {row['Info']} (Keyword: *{row['Keyword']}*)")

            st.markdown("---") # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÎ® Î³ÏÎ±Î¼Î¼Î® Ï€ÏÎ¹Î½ Ï„Î·Î½ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·
        else:
            st.info(f"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Ï€ÏÏŒÏƒÏ†Î±Ï„ÎµÏ‚ Î±Î½Î±ÎºÎ¿Î¹Î½ÏÏƒÎµÎ¹Ï‚ (Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯ÎµÏ‚ 2 Î·Î¼Î­ÏÎµÏ‚) Î³Î¹Î± Ï„Î¿ Ï„Î¼Î®Î¼Î± {selected_tmima}.")
            st.markdown("---")

        
        st.header("ğŸ” Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î Î±Î»Î±Î¹ÏŒÏ„ÎµÏÏ‰Î½ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½")
        st.info("Î“Î¹Î± Î½Î± Î²ÏÎµÎ¯Ï„Îµ ÎºÎ¬Ï„Î¹ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î® Ï€Î±Î»Î±Î¹ÏŒÏ„ÎµÏÎ¿, Ï€Î»Î·ÎºÏ„ÏÎ¿Î»Î¿Î³Î®ÏƒÏ„Îµ Ï„Î· Ï†ÏÎ¬ÏƒÎ·-ÎºÎ»ÎµÎ¹Î´Î¯ (keyword) Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰.")

        # ----------------------------------------------------------------------
        # Î£Î¥ÎÎ•Î§Î•Î™Î‘ Î¤Î—Î£ Î›ÎŸÎ“Î™ÎšÎ—Î£ Î‘ÎÎ‘Î–Î—Î¤Î—Î£Î—Î£
        # ----------------------------------------------------------------------
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï‡Î±ÏÏ„ÏÎ½ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î± Ï†Î¹Î»Ï„ÏÎ±ÏÎ¹ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
        tag_to_keyword_map, keyword_to_data_map = create_search_maps(filtered_df)
        current_available_keys = sorted(filtered_df['Keyword'].unique().tolist())
        

        user_input = st.text_input(
            'Î¤Î¹ Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± Î¼Î¬Î¸ÎµÎ¹Ï‚;', 
            placeholder='Î Î»Î·ÎºÏ„ÏÎ¿Î»ÏŒÎ³Î·ÏƒÎµ Ï€.Ï‡. ÎµÎºÎ´ÏÎ¿Î¼Î·, ÎµÏÎ³Î±ÏƒÎ¹Î±, Î²Î¹Î²Î»Î¹Î±...'
        )

        if user_input and keyword_to_data_map:
            # Î›Î¿Î³Î¹ÎºÎ® Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ 
            search_tag = normalize_text(user_input)
            matching_keywords = tag_to_keyword_map.get(search_tag, set())
            
            if matching_keywords:
                all_results = []
                
                for keyword in matching_keywords:
                    # Î¤Î¿ zip Î­Ï‡ÎµÎ¹ 6 ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±: (Info, URL, Type, Date, School, Tmima)
                    all_results.extend(keyword_to_data_map.get(keyword, [])) 

                st.success(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ **{len(all_results)}** Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Ï„Î¿ '{user_input}'.")
                
                # Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Ï„Ï‰Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ Î²Î¬ÏƒÎµÎ¹ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚
                results_list = []
                for info, url, item_type, date_obj, school, tmima in all_results:
                    results_list.append((date_obj, info, url, item_type, school, tmima))
                
                results_list.sort(key=lambda x: x[0], reverse=True) # Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Î±Î½Î¬ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± (Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î¿ Ï€ÏÏÏ„Î¿)

                for i, (date_obj, info, url, item_type, school, tmima) in enumerate(results_list, 1):
                    date_str = date_obj.strftime(DATE_FORMAT) if pd.notna(date_obj) else "Î†Î³Î½Ï‰ÏƒÏ„Î· Î—Î¼/Î½Î¯Î±"
                    header = f"**Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± {i}** (Î—Î¼/Î½Î¯Î±: {date_str})"
                    
                    if item_type.strip().lower() == 'link': 
                        link_description = info.strip()
                        link_url = url.strip()
                        if link_url:
                            st.markdown(f"{header}: ğŸ”— [{link_description}](<{link_url}>)") 
                        else:
                            st.markdown(f"{header}: âš ï¸ **Î ÏÎ¿ÏƒÎ¿Ï‡Î®:** ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· ÏƒÏ…Î½Î´Î­ÏƒÎ¼Î¿Ï… Ï‡Ï‰ÏÎ¯Ï‚ URL. Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®: {link_description}")
                    
                    elif item_type.strip().lower() == 'text':
                        st.markdown(f"{header}: ğŸ’¬ {info}")
                    
                    else:
                        st.markdown(f"{header}: Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ Î¤ÏÏ€Î¿Ï‚ ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ·Ï‚. {info}")
                        
            else:
                st.warning(f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î³Î¹Î± Ï„Î¿: '{user_input}'.")

        st.markdown("---")


elif full_df.empty:
    st.warning("Î Î±ÏÎ±ÎºÎ±Î»Ï ÏƒÏ…Î¼Ï€Î»Î·ÏÏÏƒÏ„Îµ Ï„Î¿ Google Sheet Î¼Îµ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ 'School' ÎºÎ±Î¹ 'Tmima'.")
else:
    st.info("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹Î»Î­Î¾Ï„Îµ Î£Ï‡Î¿Î»ÎµÎ¯Î¿ Î³Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹ Î· Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·.")


st.caption("Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î´Î¹Î±Î²Î¬Î¶Î¿Î½Ï„Î±Î¹ ÎºÎ±Î¹ Î³ÏÎ¬Ï†Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿ Google Sheet Î¼Î­ÏƒÏ‰ Ï„Î·Ï‚ Î²Î±ÏƒÎ¹ÎºÎ®Ï‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·Ï‚ gspread.")
